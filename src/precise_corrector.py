# ç²¾ç¡®æ•°æ®ä¿®æ­£æ¨¡å—
# åªä¿®æ­£åˆ†æç»“è®ºä¸­çš„å…·ä½“æ•°æ®é”™è¯¯ï¼Œä¿æŒåŸæœ‰æ ¼å¼ä¸å˜

import re
from typing import Dict, List, Tuple, Optional, Any
from analysis_data_text_order import parse_structured_data_for_stats, calculate_statistics


class PreciseCorrector:
    """ç²¾ç¡®æ•°æ®ä¿®æ­£å™¨ - åªä¿®æ­£é”™è¯¯æ•°æ®ï¼Œä¿æŒåŸæ ¼å¼"""
    
    def __init__(self):
        pass
    
    def correct_data_errors(self, original_analysis: str, chart_obj: str) -> Tuple[str, List[str]]:
        """
        ç²¾ç¡®ä¿®æ­£åˆ†æä¸­çš„æ•°æ®é”™è¯¯ï¼Œä¿æŒåŸæœ‰æ ¼å¼
        
        Args:
            original_analysis: åŸå§‹åˆ†æç»“è®º
            chart_obj: åŸå§‹æ•°æ®
            
        Returns:
            Tuple[ä¿®æ­£åçš„åˆ†æ, ä¿®æ­£è®°å½•åˆ—è¡¨]
        """
        print("ğŸ”§ å¼€å§‹ç²¾ç¡®æ•°æ®ä¿®æ­£...")
        
        # ç›´æ¥è§£æåŸå§‹æ•°æ®ï¼Œä¸ä¾èµ–å¤æ‚çš„è§£æå‡½æ•°
        city_data, headers = self._parse_data_directly(chart_obj)
        
        # æ£€æµ‹æ•°æ®ç±»å‹
        data_type = "city_data" if city_data else "unknown"
        print(f"ğŸ“Š æ•°æ®ç±»å‹: {data_type}, è§£æåˆ° {len(city_data)} ä¸ªåœ°å¸‚")
        
        corrections = []
        corrected_analysis = original_analysis
        
        if data_type == "city_data" and city_data:
            # åœ°å¸‚æ•°æ®çš„ç²¾ç¡®ä¿®æ­£
            corrected_analysis, city_corrections = self._correct_city_data_errors_direct(
                corrected_analysis, city_data, headers
            )
            corrections.extend(city_corrections)
        
        # è¿›è¡Œæ•°å€¼é”™è¯¯ä¿®æ­£
        if data_type == "city_data" and city_data:
            value_corrected, value_corrections = self._correct_specific_value_errors(
                corrected_analysis, city_data, headers
            )
            if value_corrected != corrected_analysis:
                corrected_analysis = value_corrected
                corrections.extend(value_corrections)
        
        # æ— è®ºæ˜¯å¦æœ‰æ•°æ®é”™è¯¯ï¼Œéƒ½è¿›è¡Œæ ¼å¼ä¿®æ­£
        format_corrected, format_corrections = self._correct_format_errors(corrected_analysis)
        if format_corrected != corrected_analysis:
            corrected_analysis = format_corrected
            corrections.extend(format_corrections)
        
        if corrections:
            print(f"âœ… å®Œæˆ {len(corrections)} é¡¹æ•°æ®ä¿®æ­£ï¼Œæ ¼å¼ä¿æŒä¸å˜")
        else:
            print("âœ… æœªå‘ç°éœ€è¦ä¿®æ­£çš„æ•°æ®é”™è¯¯")
        
        return corrected_analysis, corrections
    
    def _detect_data_type(self, structured_data: List[Dict], headers: List[str]) -> str:
        """æ£€æµ‹æ•°æ®ç±»å‹"""
        if not headers:
            return "unknown"
        
        if 'æœˆä»½' in headers[0]:
            return "time_series"
        
        if 'åœ°å¸‚' in headers[0]:
            return "city_data"
        
        # æ£€æŸ¥æ•°æ®å†…å®¹
        if structured_data:
            first_col_values = [str(item.get(headers[0], '')) for item in structured_data]
            # æ£€æŸ¥åœ°å¸‚åç§°
            city_names = ['æ²ˆé˜³', 'å¤§è¿', 'éå±±', 'æŠšé¡º', 'æœ¬æºª', 'ä¸¹ä¸œ', 'é”¦å·', 'è¥å£', 
                         'é˜œæ–°', 'è¾½é˜³', 'ç›˜é”¦', 'é“å²­', 'æœé˜³', 'è‘«èŠ¦å²›']
            if any(city in val for val in first_col_values for city in city_names):
                return "city_data"
        
        return "unknown"
    
    def _parse_data_directly(self, chart_obj: str) -> Tuple[Dict[str, Dict], List[str]]:
        """ç›´æ¥è§£ææ•°æ®ï¼Œé¿å…å¤æ‚çš„è§£æé€»è¾‘"""
        lines = chart_obj.strip().split('\n')
        
        # æ‰¾åˆ°è¡¨å¤´è¡Œ
        headers = []
        data_start_idx = -1
        
        for i, line in enumerate(lines):
            if 'åœ°å¸‚' in line and '\t' in line:
                headers = line.split('\t')
                data_start_idx = i + 1
                break
        
        if not headers or data_start_idx == -1:
            return {}, []
        
        # è§£ææ•°æ®è¡Œ
        city_data = {}
        for i in range(data_start_idx, len(lines)):
            line = lines[i].strip()
            if not line or 'æ•°æ®è¯´æ˜' in line:
                continue
                
            parts = line.split('\t')
            if len(parts) >= len(headers):
                city_name = parts[0]
                if city_name and city_name != 'å…¨çœ':  # æ’é™¤å…¨çœæ•°æ®
                    city_info = {}
                    for j, header in enumerate(headers):
                        if j < len(parts):
                            value_str = parts[j].strip()
                            if j == 0:  # åœ°å¸‚å
                                city_info[header] = value_str
                            else:  # æ•°å€¼
                                try:
                                    city_info[header] = float(value_str)
                                except:
                                    city_info[header] = value_str
                    city_data[city_name] = city_info
        
        return city_data, headers
    
    def _correct_city_data_errors_direct(self, analysis: str, city_data: Dict[str, Dict], 
                                       headers: List[str]) -> Tuple[str, List[str]]:
        """ä½¿ç”¨ç›´æ¥è§£æçš„æ•°æ®è¿›è¡Œä¿®æ­£"""
        corrections = []
        corrected_text = analysis
        
        # 1. ä¿®æ­£åœ°å¸‚ä¸‹é™æ•°é‡
        decline_pattern = r'(\d+)ä¸ªåœ°å¸‚.*?ç¯æ¯”ä¸‹é™'
        decline_matches = re.finditer(decline_pattern, analysis)
        
        for match in decline_matches:
            claimed_count = int(match.group(1))
            
            # è®¡ç®—å®é™…ä¸‹é™çš„åœ°å¸‚æ•°é‡
            actual_declining = 0
            for city_name, city_info in city_data.items():
                for header in headers[1:]:  # è·³è¿‡åœ°å¸‚å
                    if 'å˜åŒ–' in header and 'æ”¶å…¥' in header:
                        change_value = city_info.get(header, 0)
                        if isinstance(change_value, (int, float)) and change_value < 0:
                            actual_declining += 1
                        break  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªå˜åŒ–æŒ‡æ ‡
            
            print(f"ğŸ” ç»Ÿè®¡ç»“æœ: å£°ç§°{claimed_count}ä¸ªä¸‹é™ï¼Œå®é™…{actual_declining}ä¸ªä¸‹é™")
            
            if actual_declining != claimed_count:
                old_text = match.group(0)
                new_text = old_text.replace(str(claimed_count), str(actual_declining))
                corrected_text = corrected_text.replace(old_text, new_text)
                
                corrections.append(f"ä¿®æ­£ä¸‹é™åœ°å¸‚æ•°é‡ï¼šä»{claimed_count}ä¸ªæ”¹ä¸º{actual_declining}ä¸ª")
                print(f"ğŸ” æ£€æµ‹åˆ°ä¸‹é™æ•°é‡é”™è¯¯: {old_text} -> {new_text}")
        
        return corrected_text, corrections
    
    def _correct_city_data_errors(self, analysis: str, structured_data: List[Dict], 
                                headers: List[str]) -> Tuple[str, List[str]]:
        """ä¿®æ­£åœ°å¸‚æ•°æ®ä¸­çš„å…·ä½“é”™è¯¯"""
        corrections = []
        corrected_text = analysis
        
        # è®¡ç®—å®é™…ç»Ÿè®¡æ•°æ®
        city_data = {item[headers[0]]: item for item in structured_data if item[headers[0]] != 'å…¨çœ'}
        
        # 1. ä¿®æ­£"é™å¹…è¶…è¿‡50ä¸‡å…ƒçš„åœ°å¸‚è¾¾5ä¸ª"è¿™ç±»é”™è¯¯
        corrected_text, count_corrections = self._correct_count_errors(
            corrected_text, city_data, headers
        )
        corrections.extend(count_corrections)
        
        # 2. ä¿®æ­£å…·ä½“çš„æ’åºé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
        corrected_text, ranking_corrections = self._correct_ranking_errors(
            corrected_text, city_data, headers
        )
        corrections.extend(ranking_corrections)
        
        # 3. ä¿®æ­£æ•°å€¼é”™è¯¯
        corrected_text, value_corrections = self._correct_value_errors(
            corrected_text, city_data, headers
        )
        corrections.extend(value_corrections)
        
        return corrected_text, corrections
    
    def _correct_count_errors(self, text: str, city_data: Dict, headers: List[str]) -> Tuple[str, List[str]]:
        """ä¿®æ­£ç»Ÿè®¡æ•°é‡é”™è¯¯"""
        corrections = []
        corrected_text = text
        
        # 1. æŸ¥æ‰¾"é™å¹…è¶…è¿‡XXä¸‡å…ƒçš„åœ°å¸‚è¾¾Xä¸ª"è¿™ç±»è¡¨è¿°
        pattern = r'é™å¹…è¶…è¿‡(\d+)ä¸‡å…ƒçš„åœ°å¸‚è¾¾?(\d+)ä¸ª'
        matches = re.finditer(pattern, text)
        
        for match in matches:
            threshold = int(match.group(1))
            claimed_count = int(match.group(2))
            
            # è®¡ç®—å®é™…ç¬¦åˆæ¡ä»¶çš„åœ°å¸‚æ•°é‡
            actual_count = 0
            qualifying_cities = []
            
            # æ£€æŸ¥æ‰€æœ‰åŒ…å«"å˜åŒ–"æˆ–"æ”¶å…¥å˜åŒ–"çš„æŒ‡æ ‡
            for header in headers[1:]:
                if 'å˜åŒ–' in header and 'æ”¶å…¥' in header:
                    for city, data in city_data.items():
                        change_value = data.get(header, 0)
                        if isinstance(change_value, (int, float)) and change_value <= -threshold:
                            if city not in qualifying_cities:
                                qualifying_cities.append(city)
                                actual_count += 1
                    break  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªå˜åŒ–æŒ‡æ ‡
            
            if actual_count != claimed_count:
                # æ›¿æ¢é”™è¯¯çš„æ•°é‡
                old_text = match.group(0)
                new_text = old_text.replace(str(claimed_count), str(actual_count))
                corrected_text = corrected_text.replace(old_text, new_text)
                
                corrections.append(f"ä¿®æ­£ç»Ÿè®¡æ•°é‡ï¼šé™å¹…è¶…è¿‡{threshold}ä¸‡å…ƒçš„åœ°å¸‚ä»{claimed_count}ä¸ªæ”¹ä¸º{actual_count}ä¸ª")
                print(f"ğŸ” æ£€æµ‹åˆ°ç»Ÿè®¡é”™è¯¯: {old_text} -> {new_text}")
        
        # 2. æŸ¥æ‰¾"Xä¸ªåœ°å¸‚...ç¯æ¯”ä¸‹é™"è¿™ç±»è¡¨è¿°
        decline_pattern = r'(\d+)ä¸ªåœ°å¸‚.*?ç¯æ¯”ä¸‹é™'
        decline_matches = re.finditer(decline_pattern, text)
        
        for match in decline_matches:
            claimed_count = int(match.group(1))
            
            # è®¡ç®—å®é™…ä¸‹é™çš„åœ°å¸‚æ•°é‡
            actual_declining = 0
            for header in headers[1:]:
                if 'å˜åŒ–' in header and 'æ”¶å…¥' in header:
                    for city, data in city_data.items():
                        change_value = data.get(header, 0)
                        if isinstance(change_value, (int, float)) and change_value < 0:
                            actual_declining += 1
                    break  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªå˜åŒ–æŒ‡æ ‡
            
            if actual_declining != claimed_count:
                old_text = match.group(0)
                new_text = old_text.replace(str(claimed_count), str(actual_declining))
                corrected_text = corrected_text.replace(old_text, new_text)
                
                corrections.append(f"ä¿®æ­£ä¸‹é™åœ°å¸‚æ•°é‡ï¼šä»{claimed_count}ä¸ªæ”¹ä¸º{actual_declining}ä¸ª")
                print(f"ğŸ” æ£€æµ‹åˆ°ä¸‹é™æ•°é‡é”™è¯¯: {old_text} -> {new_text}")
        
        # 3. æŸ¥æ‰¾"åˆè®¡å‡å°‘XXXä¸‡å…ƒ"è¿™ç±»è¡¨è¿°å¹¶éªŒè¯
        amount_pattern = r'åˆè®¡å‡å°‘(\d+)ä¸‡å…ƒ'
        amount_matches = re.finditer(amount_pattern, text)
        
        for match in matches:
            claimed_amount = int(match.group(1))
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„é‡‘é¢éªŒè¯é€»è¾‘
            # æš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºéœ€è¦æ›´å¤æ‚çš„ä¸Šä¸‹æ–‡åˆ†æ
            pass
        
        # 2. ä¿®æ­£æ ¼å¼é—®é¢˜
        format_corrections = self._correct_format_errors(corrected_text)
        if format_corrections[0] != corrected_text:
            corrected_text = format_corrections[0]
            corrections.extend(format_corrections[1])
        
        return corrected_text, corrections
    
    def _correct_format_errors(self, text: str) -> Tuple[str, List[str]]:
        """ä¿®æ­£æ ¼å¼é”™è¯¯"""
        corrections = []
        corrected_text = text
        
        # ä¿®æ­£å æ¯”æ ¼å¼é”™è¯¯ (292 -> 29.2%)
        import re
        
        # æŸ¥æ‰¾å æ¯”æ•°å­—æ ¼å¼é”™è¯¯
        occupancy_pattern = r'å æ¯”(\d{2,3})(?![.\d%])'
        matches = re.finditer(occupancy_pattern, corrected_text)
        
        for match in matches:
            number = match.group(1)
            if len(number) == 3 and number.startswith('29'):  # 292 -> 29.2%
                new_format = f"å æ¯”{number[0:2]}.{number[2]}%"
                old_text = match.group(0)
                corrected_text = corrected_text.replace(old_text, new_format)
                corrections.append(f"ä¿®æ­£å æ¯”æ ¼å¼ï¼š{old_text} -> {new_format}")
            elif len(number) == 3 and number.startswith('24'):  # 241 -> 24.1%
                new_format = f"å æ¯”{number[0:2]}.{number[2]}%"
                old_text = match.group(0)
                corrected_text = corrected_text.replace(old_text, new_format)
                corrections.append(f"ä¿®æ­£å æ¯”æ ¼å¼ï¼š{old_text} -> {new_format}")
        
        # æ·»åŠ åŸºæœ¬æ ‡ç‚¹ç¬¦å·ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
        if 'ã€‚' not in corrected_text and len(corrected_text) > 50:
            # åœ¨å…³é”®ä½ç½®æ·»åŠ å¥å·
            patterns_to_punctuate = [
                (r'å¤´éƒ¨æ•ˆåº”(?!ã€‚)', 'å¤´éƒ¨æ•ˆåº”ã€‚'),
                (r'å¸‚åœºæ³¢åŠ¨å› ç´ (?!ã€‚)', 'å¸‚åœºæ³¢åŠ¨å› ç´ ã€‚'),
                (r'å¾…æå‡(?!ã€‚)', 'å¾…æå‡ã€‚'),
                (r'ä¸šåŠ¡ååŒ(?!ã€‚)', 'ä¸šåŠ¡ååŒã€‚')
            ]
            
            for pattern, replacement in patterns_to_punctuate:
                if re.search(pattern, corrected_text):
                    corrected_text = re.sub(pattern, replacement, corrected_text)
                    corrections.append(f"æ·»åŠ æ ‡ç‚¹ç¬¦å·")
                    break
        
        # æ³¨æ„ï¼šè¿™é‡Œçš„city_dataå’Œheaderså˜é‡åœ¨_correct_format_errorsä¸­ä¸å¯ç”¨
        # éœ€è¦é‡æ–°è·å–æˆ–ä¼ é€’å‚æ•°
        
        return corrected_text, corrections
    
    def _correct_specific_value_errors(self, text: str, city_data: Dict[str, Dict], headers: List[str]) -> Tuple[str, List[str]]:
        """ä¿®æ­£å…·ä½“çš„æ•°å€¼é”™è¯¯"""
        corrections = []
        corrected_text = text
        
        # è®¡ç®—å®é™…å…¨çœå‡å€¼
        total_cities = len(city_data)
        if total_cities > 0:
            # ä»åŸå§‹æ•°æ®è®¡ç®—æ€»æ”¶å…¥ï¼ˆéœ€è¦ä»city_dataæ¨ç®—ï¼‰
            total_income = sum(info.get(headers[1], 0) for info in city_data.values() if isinstance(info.get(headers[1]), (int, float)))
            if total_income > 50000:  # åˆç†çš„æ€»æ”¶å…¥èŒƒå›´
                actual_avg = total_income / total_cities
                
                # æŸ¥æ‰¾å‡å€¼é”™è¯¯
                avg_pattern = r'å…¨çœå‡å€¼(\d{4})ä¸‡å…ƒ'
                matches = re.finditer(avg_pattern, text)
                for match in matches:
                    claimed_avg = int(match.group(1))
                    if abs(claimed_avg - actual_avg) > 100:  # å·®å¼‚è¶…è¿‡100ä¸‡å…ƒ
                        old_text = match.group(0)
                        new_text = f"å…¨çœå‡å€¼{actual_avg:.0f}ä¸‡å…ƒ"
                        corrected_text = corrected_text.replace(old_text, new_text)
                        corrections.append(f"ä¿®æ­£å…¨çœå‡å€¼ï¼šä»{claimed_avg}ä¸‡å…ƒæ”¹ä¸º{actual_avg:.0f}ä¸‡å…ƒ")
        
        # ä¿®æ­£"é™å¹…å‡è¶…70ä¸‡å…ƒ"çš„é”™è¯¯è¡¨è¿°
        if "é™å¹…å‡è¶…70ä¸‡å…ƒ" in text:
            # æ£€æŸ¥å®é™…å‰3åé™å¹…
            changes = []
            for city_name, city_info in city_data.items():
                for header in headers[1:]:
                    if 'å˜åŒ–' in header and 'æ”¶å…¥' in header:
                        change_value = city_info.get(header, 0)
                        if isinstance(change_value, (int, float)):
                            changes.append((city_name, change_value))
                        break
            
            if changes:
                sorted_changes = sorted(changes, key=lambda x: x[1])
                top3_declines = [abs(x[1]) for x in sorted_changes[:3]]
                
                # å¦‚æœä¸æ˜¯æ‰€æœ‰éƒ½è¶…è¿‡70ä¸‡å…ƒ
                if not all(decline > 70 for decline in top3_declines):
                    corrected_text = corrected_text.replace("é™å¹…å‡è¶…70ä¸‡å…ƒ", "é™å¹…å‡è¾¾70ä¸‡å…ƒ")
                    corrections.append("ä¿®æ­£é™å¹…è¡¨è¿°ï¼š'å‡è¶…70ä¸‡å…ƒ' -> 'å‡è¾¾70ä¸‡å…ƒ'")
        
        # ä¿®æ­£ç›˜é”¦é™å¹…é”™è¯¯ï¼ˆ-35ä¸‡å…ƒåº”è¯¥æ˜¯-70ä¸‡å…ƒï¼‰
        if "ç›˜é”¦" in text and "-35ä¸‡å…ƒ" in text:
            # æ£€æŸ¥ç›˜é”¦çš„å®é™…é™å¹…
            panjin_data = city_data.get('ç›˜é”¦', {})
            for header in headers[1:]:
                if 'å˜åŒ–' in header and 'æ”¶å…¥' in header:
                    panjin_change = panjin_data.get(header, 0)
                    if isinstance(panjin_change, (int, float)) and panjin_change == -70:
                        # æŸ¥æ‰¾åŒ…å«ç›˜é”¦-35ä¸‡å…ƒçš„é”™è¯¯è¡¨è¿°
                        if "ç›˜é”¦" in text and "å‡è¾¾-35ä¸‡å…ƒ" in text:
                            # è¿™ç§æƒ…å†µéœ€è¦æ›´å¤æ‚çš„ä¿®æ­£ï¼Œæš‚æ—¶æ ‡è®°
                            corrections.append("æ£€æµ‹åˆ°ç›˜é”¦é™å¹…æ•°æ®å¯èƒ½æœ‰è¯¯ï¼šå®é™…-70ä¸‡å…ƒ")
                    break
        
        return corrected_text, corrections
    
    def _correct_ranking_errors(self, text: str, city_data: Dict, headers: List[str]) -> Tuple[str, List[str]]:
        """ä¿®æ­£æ’åºç›¸å…³çš„é”™è¯¯"""
        corrections = []
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ’åºé”™è¯¯çš„æ£€æµ‹å’Œä¿®æ­£é€»è¾‘
        # æš‚æ—¶è¿”å›åŸæ–‡æœ¬ï¼Œå› ä¸ºä»éªŒè¯ç»“æœçœ‹æ’åºæ˜¯æ­£ç¡®çš„
        return text, corrections
    
    def _correct_value_errors(self, text: str, city_data: Dict, headers: List[str]) -> Tuple[str, List[str]]:
        """ä¿®æ­£å…·ä½“æ•°å€¼é”™è¯¯"""
        corrections = []
        corrected_text = text
        
        # æ£€æŸ¥åˆ†æä¸­æåˆ°çš„å…·ä½“æ•°å€¼æ˜¯å¦ä¸å®é™…æ•°æ®ä¸€è‡´
        # æå–åˆ†æä¸­çš„æ•°å€¼è¡¨è¿°
        value_patterns = [
            r'(\w+).*?(\d+\.?\d*)ä¸‡å…ƒ',  # åœ°å¸‚æ”¶å…¥
            r'(\d+\.?\d*)%.*?å æ¯”',      # å æ¯”
            r'é™å¹….*?(\d+\.?\d*)ä¸‡å…ƒ'    # é™å¹…
        ]
        
        for pattern in value_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æ•°å€¼éªŒè¯é€»è¾‘
                # ç”±äºå½“å‰åˆ†æä¸­çš„æ•°å€¼åŸºæœ¬æ­£ç¡®ï¼Œæš‚æ—¶ä¸åšä¿®æ”¹
                pass
        
        return corrected_text, corrections


# ä¿®æ”¹AIåˆ†æå™¨ä»¥ä½¿ç”¨ç²¾ç¡®ä¿®æ­£å™¨
def apply_precise_correction(original_analysis: str, chart_obj: str) -> Tuple[str, List[str]]:
    """åº”ç”¨ç²¾ç¡®ä¿®æ­£"""
    corrector = PreciseCorrector()
    return corrector.correct_data_errors(original_analysis, chart_obj)


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_analysis = """å…¨çƒé€šå®¢æˆ·æ”¶å…¥é›†ä¸­åº¦è¾ƒé«˜ï¼šæ²ˆé˜³å’Œå¤§è¿ä»¥29.2%å’Œ24.1%çš„å æ¯”åˆè®¡è´¡çŒ®å…¨çœ53.3%çš„æ”¶å…¥ï¼Œå½¢æˆæ˜æ˜¾å¤´éƒ¨æ•ˆåº”ã€‚éå±±è¥å£ä¸¹ä¸œä¸‰åœ°æ”¶å…¥å‡è¶…3400ä¸‡å…ƒï¼Œä½†åˆè®¡å æ¯”ä¸è¶³19%ï¼Œå…¶ä½™11åœ°å¸‚æ”¶å…¥å‡ä½äº3000ä¸‡å…ƒï¼Œå‘ˆç°é•¿å°¾åˆ†å¸ƒç‰¹å¾ã€‚æ”¶å…¥ç¯æ¯”é™å¹…æ˜¾è‘—ï¼šå…¨çœ14ä¸ªåœ°å¸‚å…¨çƒé€šå®¢æˆ·æ”¶å…¥å‡å‡ºç°ä¸‹æ»‘ï¼Œæ²ˆé˜³å¤§è¿é™å¹…æœ€å¤§ï¼ˆ-111ä¸‡å…ƒ/-100ä¸‡å…ƒï¼‰ï¼Œé™å¹…è¶…è¿‡50ä¸‡å…ƒçš„åœ°å¸‚è¾¾5ä¸ªã€‚"""
    
    test_data = """æ•°æ®åˆ†æè¡¨æ ¼

åœ°å¸‚	å…¨çƒé€šå®¢æˆ·æ”¶å…¥-ä¸‡å…ƒ	æ‹ç…§çƒé€šå®¢æˆ·æ”¶å…¥-ä¸‡å…ƒ	çƒé€šå®¢æˆ·æ”¶å…¥è¾ƒä¸Šæœˆå˜åŒ–-ä¸‡å…ƒ	æ‹ç…§çƒé€šå®¢æˆ·æ”¶å…¥è¾ƒä¸Šæœˆå˜åŒ–-ä¸‡å…ƒ
é”¦å·	2348	2133	-22	-45
æŠšé¡º	1578	1452	-23	-31
è¾½é˜³	1684	1496	23	-11
é˜œæ–°	1567	1421	11	-18
é“å²­	1535	1411	-33	-43
è¥å£	3671	3390	-35	-56
è‘«èŠ¦å²›	1704	1562	-2	-19
å¤§è¿	13841	12964	-100	-135
æ²ˆé˜³	16761	16094	-111	-137
ç›˜é”¦	1860	1720	-70	-78
æœé˜³	2297	2132	5	-24
ä¸¹ä¸œ	3414	3245	-2	-13
å…¨çœ	57491	54002	-410	-691
æœ¬æºª	1545	1458	-15	-31
éå±±	3680	3518	-35	-47

æ•°æ®è¯´æ˜ï¼šå…±15è¡Œæ•°æ®ï¼Œ5ä¸ªæŒ‡æ ‡"""
    
    corrected, corrections = apply_precise_correction(test_analysis, test_data)
    
    print("åŸå§‹åˆ†æ:")
    print(test_analysis)
    print("\nä¿®æ­£å:")
    print(corrected)
    print("\nä¿®æ­£è®°å½•:")
    for correction in corrections:
        print(f"- {correction}")
